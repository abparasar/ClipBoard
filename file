from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("facebook/bart-large")

# Filter based on tokenized length
df = df[df["dialogue"].apply(lambda x: len(tokenizer(x, add_special_tokens=False)["input_ids"]) >= 20)]