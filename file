import json
import torch
from torch.utils.data import Dataset
from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments
from datasets import load_dataset, DatasetDict, Dataset

# Config paths
model_path = "./model"
data_path = "./data"

# Load tokenizer and model
tokenizer = BartTokenizer.from_pretrained(model_path)
model = BartForConditionalGeneration.from_pretrained(model_path)

# Load DialogSum JSONL files into HuggingFace Datasets
def load_jsonl_dataset(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        data = [json.loads(line) for line in f]
    return Dataset.from_list(data)

dataset = DatasetDict({
    "train": load_jsonl_dataset(f"{data_path}/train.jsonl"),
    "validation": load_jsonl_dataset(f"{data_path}/val.jsonl"),
    "test": load_jsonl_dataset(f"{data_path}/test.jsonl")
})

# Preprocess the dataset
max_input_length = 1024
max_target_length = 128

def preprocess(example):
    inputs = tokenizer(
        example["dialogue"],
        max_length=max_input_length,
        truncation=True,
        padding="max_length"
    )
    targets = tokenizer(
        example["summary"],
        max_length=max_target_length,
        truncation=True,
        padding="max_length"
    )
    inputs["labels"] = targets["input_ids"]
    return inputs

tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=dataset["train"].column_names)

# Training arguments
training_args = TrainingArguments(
    output_dir="./results",
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    logging_dir="./logs",
    logging_steps=50,
    fp16=torch.cuda.is_available(),  # Mixed precision training if GPU supports it
    report_to="none"
)

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"],
    tokenizer=tokenizer
)

# Fine-tune
trainer.train()

# Save the final model
trainer.save_model("./finetuned-bart-dialogsum")
tokenizer.save_pretrained("./finetuned-bart-dialogsum")