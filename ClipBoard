# train.py

import os
import torch
import pandas as pd
from sklearn.model_selection import train_test_split, ParameterSampler
from datasets import Dataset, load_from_disk
from transformers import (
    PegasusTokenizer,
    PegasusForConditionalGeneration,
    DataCollatorForSeq2Seq,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments
)
import evaluate
import numpy as np

# âœ… DDP env
local_rank = int(os.environ.get("LOCAL_RANK", 0))
world_size = int(os.environ.get("WORLD_SIZE", 1))
device = torch.device("cuda", local_rank) if torch.cuda.is_available() else torch.device("cpu")

print(f"Rank {local_rank}/{world_size} on {device}")

# âœ… Load prepared dataset OR recreate here
df = pd.read_csv("/projectspace/zkfq4hl/data/titlesum.csv").head(1000)
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)

tokenizer = PegasusTokenizer.from_pretrained("google/pegasus-large")
model = PegasusForConditionalGeneration.from_pretrained("google/pegasus-large").to(device)

# âœ… Preprocess
def preprocess(examples):
    inputs = examples["dialogue"]
    model_inputs = tokenizer(
        inputs, max_length=1024, truncation=True, padding="max_length"
    )
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(
            examples["one_liner"],
            max_length=1024, truncation=True, padding="max_length"
        )
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

train_ds = Dataset.from_pandas(train_df).map(preprocess, batched=True)
val_ds = Dataset.from_pandas(val_df).map(preprocess, batched=True)

# âœ… Collator & metric
data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)
rouge = evaluate.load("rouge")

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    if isinstance(predictions, tuple):
        predictions = predictions[0]
    predictions = np.where(predictions >= 0, predictions, tokenizer.pad_token_id)
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    return {k: round(v, 4) for k, v in rouge.compute(predictions=decoded_preds, references=decoded_labels).items()}

# âœ… Random search
param_dist = {
    "learning_rate": [1e-5, 3e-5, 5e-5],
    "per_device_train_batch_size": [2, 4],
    "num_train_epochs": [2, 3],
    "weight_decay": [0.0, 0.01],
    "warmup_steps": [0, 500],
}

param_sampler = ParameterSampler(param_dist, n_iter=5, random_state=42)

best_metric = -1
best_params = None

for i, params in enumerate(param_sampler):
    run_name = f"run_{i+1}_lr{params['learning_rate']}_bs{params['per_device_train_batch_size']}_ep{params['num_train_epochs']}_wd{params['weight_decay']}_wu{params['warmup_steps']}"
    output_dir = f"./pegasus_random_runs/{run_name}"

    training_args = Seq2SeqTrainingArguments(
        output_dir=output_dir,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        learning_rate=params["learning_rate"],
        per_device_train_batch_size=params["per_device_train_batch_size"],
        per_device_eval_batch_size=params["per_device_train_batch_size"],
        num_train_epochs=params["num_train_epochs"],
        weight_decay=params["weight_decay"],
        warmup_steps=params["warmup_steps"],
        predict_with_generate=True,
        generation_max_length=1024,
        fp16=torch.cuda.is_available(),
        save_total_limit=1,
        logging_dir=f"{output_dir}/logs",
        logging_steps=50,
        report_to="none",
        load_best_model_at_end=True,
        metric_for_best_model="eval_rougeL",
        greater_is_better=True
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics,
    )

    if local_rank == 0:
        print(f"\nðŸš€ Starting run {i+1}/{5}: {run_name}\n{'-'*60}")

    trainer.train()
    metrics = trainer.evaluate()
    rougeL = metrics.get("eval_rougeL", 0)

    if local_rank == 0:
        print(f"Run {run_name} â†’ ROUGE-L: {rougeL:.4f}")

    if rougeL > best_metric:
        best_metric = rougeL
        best_params = params

if local_rank == 0:
    print("\nâœ… Finished all runs.")
    print(f"Best ROUGE-L: {best_metric:.4f}")
    print(f"Best Params: {best_params}")