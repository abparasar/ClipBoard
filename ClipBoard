Deepfake Attack Detection targets more sophisticated forms of identity spoofing, particularly those generated using AI-based facial synthesis. Fraudsters may use deepfake or AI-generated faces to deceive verification systems that must comply with stringent Know Your Customer (KYC) regulations. Mitek’s DFD module identifies digital forgeries such as AI face swaps, synthetic media created by generative models (e.g., Midjourney, Stable Diffusion), and digitally manipulated images that include overlays, screenshots, or watermarks. The system analyzes the selfie image and outputs a probability value representing the likelihood that the image is a deepfake. The model score ranges from 0 (deepfake) to 100 (live), with a threshold of 50. A selfie scoring below 50 is considered a deepfake and returns a Boolean result of “0,” while a score of 50 or higher is considered live and returns “1.” This deepfake detection mechanism significantly enhances the robustness of the verification process by addressing emerging threats from generative AI manipulation.