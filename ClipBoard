import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer, softmax

# Load the BART-large MNLI model from local directory
model_path = './my_local_model/'  # Replace with your local path
model = AutoModelForSequenceClassification.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# Define the list of premises and hypotheses
premises = [
    "A woman is sitting at a desk, typing on her laptop.",
    "A group of kids is playing soccer on the field.",
    "A man is cooking dinner in the kitchen."
]

hypotheses = [
    "The woman is working on her computer.",
    "The kids are practicing for a soccer match.",
    "The man is reading a book."
]

# Iterate over each premise-hypothesis pair
for i, (premise, hypothesis) in enumerate(zip(premises, hypotheses)):
    # Preprocess the input using the tokenizer
    inputs = tokenizer.encode_plus(premise, hypothesis, return_tensors='pt', truncation=True)

    # Forward pass through the model
    with torch.no_grad():
        outputs = model(**inputs)

    # Get the logits
    logits = outputs.logits

    # Apply softmax to get the probabilities
    probs = softmax(logits, dim=1)

    # Get the predicted class (0: contradiction, 1: neutral, 2: entailment)
    predicted_class = torch.argmax(probs, dim=1).item()

    # Define labels for the MNLI model
    mnli_labels = ['contradiction', 'neutral', 'entailment']

    # Check if the predicted class is entailment
    is_entailment = mnli_labels[predicted_class] == 'entailment'

    # Extract probabilities for each label
    contradiction_prob = probs[0][0].item()
    neutral_prob = probs[0][1].item()
    entailment_prob = probs[0][2].item()

    # Print the results for each pair
    print(f"\nPair {i+1}:")
    print(f"Premise: {premise}")
    print(f"Hypothesis: {hypothesis}")
    print(f"Predicted label: {mnli_labels[predicted_class]}")
    print(f"Entailment: {is_entailment}")
    print(f"Probabilities: Contradiction = {contradiction_prob:.4f}, Neutral = {neutral_prob:.4f}, Entailment = {entailment_prob:.4f}")