import numpy as np
import torch
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

def visualize_with_cosine_similarity(words, flattened_embedding, key, closest_words):
    # Create a list of embeddings to visualize (key words + their closest words)
    embeddings_to_plot = []
    labels = []

    for k in key:
        embeddings_to_plot.append(flattened_embedding[words.index(k)].numpy())  # Key word embedding
        labels.append(k)
        
        for closest_word in closest_words[k]:
            embeddings_to_plot.append(flattened_embedding[words.index(closest_word)].numpy())  # Closest word embedding
            labels.append(closest_word)
    
    embeddings_to_plot = np.array(embeddings_to_plot)

    # Compute the cosine similarity matrix
    cosine_sim_matrix = cosine_similarity(embeddings_to_plot)

    # Compute cosine distance (1 - similarity)
    cosine_dist_matrix = 1 - cosine_sim_matrix

    # Use t-SNE with the precomputed distance matrix
    tsne = TSNE(n_components=2, metric="precomputed", random_state=42)
    reduced_embeddings = tsne.fit_transform(cosine_dist_matrix)

    # Plot the result
    plt.figure(figsize=(10, 10))
    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c='blue', marker='o')

    # Highlight the key words in red
    for i, label in enumerate(labels):
        if label in key:
            plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1], c='red', marker='x', s=100)
            plt.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], label, fontsize=12, color='red')
        else:
            plt.text(reduced_embeddings[i, 0], reduced_embeddings[i, 1], label, fontsize=9, color='blue')

    plt.title("t-SNE Visualization with Cosine Similarity")
    plt.show()

# Example usage
words = [...]  # Your list of 5676 words
flattened_embedding = torch.tensor([...])  # Your tensor of embeddings
key = ['word1', 'word2', 'word3']  # Your list of 3 key words

# closest_words is the result from the previous code (find_closest_words function)
closest_words = {...}  # Dictionary of closest words for each key

# Visualize the closest words using cosine similarity
visualize_with_cosine_similarity(words, flattened_embedding, key, closest_words)