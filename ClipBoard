import pandas as pd
from transformers import BertTokenizer
from tqdm import tqdm

# Load data
data = pd.read_parquet('expanded_dataframe.parquet')

# Initialize tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize and encode with progress tracking
def tokenize_and_encode(texts, tokenizer, batch_size=1000):
    encodings = {'input_ids': [], 'attention_mask': []}
    num_batches = (len(texts) + batch_size - 1) // batch_size
    for i in tqdm(range(num_batches), desc="Tokenizing and Encoding"):
        batch_texts = texts[i*batch_size:(i+1)*batch_size]
        batch_encodings = tokenizer(batch_texts, truncation=True, padding=True, return_tensors='pt')
        for key in encodings:
            encodings[key].append(batch_encodings[key])
    
    # Concatenate the list of tensors into a single tensor
    for key in encodings:
        encodings[key] = torch.cat(encodings[key], dim=0)
    
    return encodings

# Tokenize and encode training and test data with progress bar
train_encodings = tokenize_and_encode(data['Utterances'], tokenizer)
test_encodings = tokenize_and_encode(data['Utterances'], tokenizer)