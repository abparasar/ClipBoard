Encoder-decoder attention helps the decoder focus on relevant parts of the input (from the encoder) while generating each output word.