import torch
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# Example tensor with shape [10000, 24, 600]
# For demonstration purposes, we'll create a random tensor
tensor = torch.randn(10000, 24, 600)

# Reshape tensor to 2D array [10000*24, 600] for dimensionality reduction
tensor_reshaped = tensor.view(-1, 600).numpy()  # Shape: [240000, 600]

# Dimensionality Reduction using PCA
pca = PCA(n_components=50)
pca_result = pca.fit_transform(tensor_reshaped)  # Shape: [240000, 50]

# Further reduce to 2D using t-SNE
tsne = TSNE(n_components=2, random_state=0)
tsne_result = tsne.fit_transform(pca_result)  # Shape: [240000, 2]

# Plotting the 2D result
plt.figure(figsize=(10, 8))
plt.scatter(tsne_result[:, 0], tsne_result[:, 1], s=1, alpha=0.5)
plt.title('t-SNE visualization of Word Embeddings')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.show()