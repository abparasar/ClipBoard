from sklearn.metrics import f1_score

# Example true labels and predictions
y_true = [0, 1, 2, 2, 1, 0]  # Replace with your true labels
y_pred = [0, 2, 1, 2, 0, 0]  # Replace with your predicted labels

# Calculate macro F1 score
macro_f1 = f1_score(y_true, y_pred, average='macro')
print(f'Macro F1 Score: {macro_f1}')

# Calculate micro F1 score
micro_f1 = f1_score(y_true, y_pred, average='micro')
print(f'Micro F1 Score: {micro_f1}')

# Calculate macro F0.5 score
macro_f05 = f1_score(y_true, y_pred, average='macro', beta=0.5)
print(f'Macro F0.5 Score: {macro_f05}')

# Calculate micro F0.5 score
micro_f05 = f1_score(y_true, y_pred, average='micro', beta=0.5)
print(f'Micro F0.5 Score: {micro_f05}')