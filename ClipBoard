from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb

# Initialize XGBoost classifier with GPU tree method
xgb_model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0)  # Use 'gpu_hist' for GPU

# Parameter grid for RandomizedSearchCV
param_grid = {
    'max_depth': [3, 5, 7, 9, 10],
    'min_child_weight': [1, 3, 5, 7, 10],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'eta': [0.01, 0.05, 0.1, 0.2, 0.3],
    'n_estimators': [100, 300, 500, 700, 1000],
    'gamma': [0, 0.1, 0.5, 1, 2, 5],
    'lambda': [0.01, 0.1, 1, 5, 10],
    'alpha': [0, 0.1, 1, 5, 10]
}

# Randomized search for hyperparameter tuning
random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid,
                                   scoring='f1_macro', n_iter=50, cv=3, verbose=1, n_jobs=-1)

# Fit the random search model on GPU
random_search.fit(X_train, y_train)

# Print the best parameters
print(f"Best Parameters: {random_search.best_params_}")

# Make predictions
preds = random_search.best_estimator_.predict(X_test)