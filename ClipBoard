To address this bias, out-of-sample data was independently labeled by two human annotators to ensure a more objective evaluation of the modelâ€™s performance