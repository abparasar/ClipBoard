import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import re
from tqdm import tqdm

# === CONFIGURATION ===
MODEL_PATH = "/path/to/your/llama-70b"  # üîÅ Replace with local model directory
INPUT_FILE = "your_file.xlsx"           # üîÅ Replace with your input Excel file
OUTPUT_FILE = "llama70b_summary_scores.xlsx"

# === Load Excel File ===
df = pd.read_excel(INPUT_FILE)

# === Load Tokenizer and Model on GPU ===
print("Loading LLaMA 70B model...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    device_map="auto",
    torch_dtype=torch.float16,
    trust_remote_code=True
)

llm = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=100)

# === Prompt Template Function ===
def build_prompt(row):
    transcript = row['cumulative transcript'][:1024]  # Limit to 1024 characters
    return f"""You are an expert summarization evaluator.

[Input Transcript]
{transcript}

Model A Summary:
{row['bart prediction']}

Model B Summary:
{row['champion prediction']}

Rate each summary on a scale of 1 to 10 based on:
- Faithfulness to the input
- Conciseness
- Fluency

Respond in this format:
Model A: <score>/10
Model B: <score>/10
"""

# === Initialize Score Lists ===
bart_scores = []
champion_scores = []

# === Evaluate Each Row with Progress Bar ===
print("Evaluating summaries with LLaMA 70B...\n")
for _, row in tqdm(df.iterrows(), total=len(df)):
    prompt = build_prompt(row)
    try:
        output = llm(prompt)[0]['generated_text']
    except Exception as e:
        output = ""
        print(f"Error in row: {e}")

    # Extract scores using regex
    match_a = re.search(r'Model A:\s*([\d\.]+)/10', output)
    match_b = re.search(r'Model B:\s*([\d\.]+)/10', output)

    score_a = float(match_a.group(1)) if match_a else None
    score_b = float(match_b.group(1)) if match_b else None

    bart_scores.append(score_a)
    champion_scores.append(score_b)

# === Save Output with Scores ===
df['bart_score'] = bart_scores
df['champion_score'] = champion_scores
df.to_excel(OUTPUT_FILE, index=False)
print(f"\n‚úÖ Scores saved to {OUTPUT_FILE}")

# === Print Final Averages ===
print("\n--- AVERAGE SCORES ---")
print(f"BART Score:     {df['bart_score'].mean():.2f}")
print(f"Champion Score: {df['champion_score'].mean():.2f}")