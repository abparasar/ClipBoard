# Replace your old highlight_pdf_matches with this robust version (same name)
# Requires: pip install pymupdf
import fitz
import re
from pathlib import Path
from typing import Tuple, List, Dict, Optional
from math import inf

def _rect_union(rects: List[fitz.Rect]) -> Optional[fitz.Rect]:
    if not rects:
        return None
    x0 = min(r.x0 for r in rects)
    y0 = min(r.y0 for r in rects)
    x1 = max(r.x1 for r in rects)
    y1 = max(r.y1 for r in rects)
    return fitz.Rect(x0, y0, x1, y1)

def _normalize_for_match(s: str) -> str:
    s2 = s.lower().strip()
    s2 = s2.replace("\u2019", "'").replace("\u201c", '"').replace("\u201d", '"')
    s2 = s2.replace("\u2013", "-").replace("\u2014", "-")
    s2 = re.sub(r"\s+", " ", s2)
    s2 = re.sub(r"[“”‘’«»]", "", s2)
    s2 = s2.strip(' \t\n\r"\'.,;:()[]{}')
    return s2

def highlight_pdf_matches(pdf_path: Path,
                          matches: List[Dict],
                          out_path: Optional[Path] = None,
                          highlight_color: Tuple[float,float,float] = (1, 0.8, 0.0),
                          mark_opacity: float = 0.35,
                          debug: bool = False):
    """
    Robust highlight: tries exact search, snippet search, then word-bbox sequence fallback,
    then token-union fallback. Writes a new PDF with rectangle annotations (highlights).
    - pdf_path: Path to original PDF
    - matches: list of dicts containing at least 'pdf_page' (1-indexed) and 'pdf_sentence'
    - out_path: where to save highlighted PDF; default: originalname_highlighted.pdf
    - highlight_color: RGB tuple (0..1)
    - mark_opacity: 0..1
    - debug: if True, prints diagnostics for misses
    """
    if out_path is None:
        out_path = pdf_path.with_name(pdf_path.stem + "_highlighted.pdf")

    doc = fitz.open(str(pdf_path))
    page_to_matches = {}
    for m in matches:
        try:
            p = int(m["pdf_page"])
        except Exception:
            # skip invalid page info
            if debug:
                print("Skipping match with invalid page:", m)
            continue
        page_to_matches.setdefault(p, []).append(m)

    for page_num, page_matches in page_to_matches.items():
        page = doc[page_num - 1]
        # list of page words: tuples (x0,y0,x1,y1, text, block_no, line_no, word_no)
        words = page.get_text("words")
        # normalized page word list for lookups
        page_words = []
        for w in words:
            x0,y0,x1,y1, txt, blockno, lineno, wordno = w
            page_words.append({
                "text": txt,
                "norm": _normalize_for_match(txt),
                "rect": fitz.Rect(x0,y0,x1,y1),
                "idx": (blockno, lineno, wordno)
            })
        pw_norms = [pw["norm"] for pw in page_words]
        page_text_norm_joined = " ".join(pw_norms)

        for m in page_matches:
            target = (m.get("pdf_sentence") or "").strip()
            if not target:
                if debug:
                    print(f"[page {page_num}] empty target sentence, skipping.")
                continue
            found_rects = []

            # 1) Try exact search
            try:
                rects = page.search_for(target, hit_max=64)
                if rects:
                    found_rects = rects
                    if debug:
                        print(f"[page {page_num}] exact search found {len(rects)} rects")
            except Exception as e:
                if debug:
                    print("exact search error:", e)

            # 2) Snippet search (first up to 120 chars)
            if not found_rects:
                snippet = target[:120].strip()
                if len(snippet) > 6:
                    try:
                        rects = page.search_for(snippet, hit_max=64)
                        if rects:
                            found_rects = rects
                            if debug:
                                print(f"[page {page_num}] snippet search found {len(rects)} rects")
                    except Exception as e:
                        if debug:
                            print("snippet search error:", e)

            # 3) Word-sequence bbox fallback
            if not found_rects:
                target_norm = _normalize_for_match(target)
                target_tokens = [t for t in re.split(r'\s+', target_norm) if t]
                if len(target_tokens) >= 3 and page_words:
                    # First try to find exact token subsequence of first up-to-8 tokens
                    N_head = min(8, len(target_tokens))
                    head = target_tokens[:N_head]
                    # try sliding window for exact head match
                    matched = False
                    for i in range(len(pw_norms) - N_head + 1):
                        if pw_norms[i:i+N_head] == head:
                            # expand j while matches continue
                            j = i + N_head
                            k = N_head
                            while j < len(pw_norms) and k < len(target_tokens) and pw_norms[j] == target_tokens[k]:
                                j += 1; k += 1
                            rects_seq = [page_words[t]["rect"] for t in range(i, j)]
                            union = _rect_union(rects_seq)
                            if union:
                                found_rects = [union]
                                matched = True
                                if debug:
                                    print(f"[page {page_num}] head token subsequence matched at {i}-{j-1}")
                                break
                    # if not matched, try a looser sequence of at least 3 tokens in order
                    if not matched:
                        for i in range(len(pw_norms)):
                            if pw_norms[i] == target_tokens[0]:
                                j = i+1
                                k = 1
                                rects_seq = [page_words[i]["rect"]]
                                while j < len(pw_norms) and k < len(target_tokens) and (pw_norms[j] == target_tokens[k]):
                                    rects_seq.append(page_words[j]["rect"])
                                    j += 1; k += 1
                                if k >= 3:
                                    union = _rect_union(rects_seq)
                                    if union:
                                        found_rects = [union]
                                        if debug:
                                            print(f"[page {page_num}] loose sequence matched at {i}-{j-1}")
                                        break

            # 4) Token-union fallback: search for a few long tokens and union their rects
            if not found_rects and len(target) > 20:
                tok_candidates = [t for t in re.split(r'\s+', target) if len(t) > 6][:4]
                token_rects = []
                for tok in tok_candidates:
                    try:
                        rlist = page.search_for(tok, hit_max=16)
                        if rlist:
                            token_rects.extend(rlist)
                    except Exception:
                        pass
                if token_rects:
                    union = _rect_union(token_rects)
                    if union:
                        found_rects = [union]
                        if debug:
                            print(f"[page {page_num}] token-union fallback found {len(token_rects)} rects")

            # Draw annotations for found rects
            if found_rects:
                for r in found_rects:
                    ann = page.add_rect_annot(r)
                    ann.set_colors(stroke=highlight_color, fill=highlight_color)
                    ann.set_opacity(mark_opacity)
                    ann.set_border(width=0)
                    ann.update()
            else:
                if debug:
                    print(f"[page {page_num}] Could NOT find rects for target (len {len(target)}).")
                    try:
                        page_text = page.get_text("text") or "(no page text)"
                        preview = page_text[:1000].replace("\n"," ")
                        print("Page text preview:", preview)
                        print("Target preview:", target[:200])
                    except Exception as e:
                        print("Error getting page text for debug:", e)

    # Save new PDF
    doc.save(str(out_path))
    doc.close()
    return out_path